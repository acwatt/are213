---
title: "ARE 213 PS 2b"
author: "S. Sung, H. Husain, T. Woolley, A. Watt"
email: aaron@acwatt.net
date: "2021-11-23"
output:
  pdf_document:
    toc: true
    toc_depth: 2
header-includes:
   - \usepackage{dcolumn}
   - \usepackage{amsmath}
   - \usepackage{floatrow}
   - \floatsetup[figure]{capposition=top}
   - \usepackage{float}
   - \floatstyle{plaintop}
   - \restylefloat{table}
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'ARE_213_PS2b.pdf')) })
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = F)
```
<!--
R version 3.6.3 (2020-02-29)
Purpose of script: run code necessary for ps2b for ARE 213

Notes: Need to open ps2b.Rmd from the ps2b folder (without Rstudio being started first)
if Rstudio is already started, the working directory will not be set
to the ps2b/ folder

\usepackage{dcolumn}: dcolumn is needed in latex compilation for multicolumn tables
-->

```{r Settings}
# stargazer table type (html, latex, or text)
# Change to latex when outputting to PDF, html when outputting to html
table_type = "latex"

```




```{r packages, include=F}
# install.packages("Synth")
# install.packages('kableExtra')
library(tidyverse)
library(haven)
library(stargazer)
library(ggplot2)
library(tinytex)
library(Synth)
library(kableExtra)
# library(plm)
# library(lmtest)
# library(sandwich)
# library(gridExtra)
# library(grid)
# library(gtable)
library(fastDummies)
# library(EnvStats)
```



\newpage
<!--=========================================================================-->
# Problem 1
<!--=========================================================================-->
**We first estimate an event study specification.**

## Part (a)
**First determine the minimum and maximum event time values that you can
estimate in this data set. Code up a separate event time indicator for each
possible value of event time in the data set. Estimate an event study regression
using all the event time indicators. What happens?**
\vspace{1em}


```{r Load Data, eval=T}
# Load data from PS2a with previous log variables
data = read_dta('traffic_safety2.dta') %>%
    mutate(fat_pc = fatalities/population,
           ln_fat_pc = log(fat_pc),
           ln_tvmt_pc = log(totalvmt/population),
           ln_precip = log(precip),
           ln_rspeed = log(rural_speed), 
           ln_uspeed = log(urban_speed))

```


Table \ref{tab:max-min-event-times-table} lists the minimum and maximum event
times that exist in the data for states that enacted a primary seat belt law in
our study period (1981-2003).

```{r Determine event time values}
# Create list of event dates for states that passed primary laws in our study
event_dates = data %>%
    group_by(state) %>%
    mutate(event = primary - lag(primary), # event=1 ==> first year primary=1
           event_year = year) %>%
    filter(event == 1) %>%
    select(state, event_year)

# Add year of primary event and event time (t) to dataframe
data = data %>%
    left_join(event_dates, by='state') %>%
    mutate(j = ifelse(is.na(event_year), 99, year - event_year))
    # t = 99 ==> control state (doesn't pass primary during study period)

# Table of max and min event times
# Shouldn't these be our event study thresholds?
df_temp = data %>%
    filter(j < 99) %>%
    group_by(state) %>%
    summarize(min_j = min(j), max_j = max(j))

max_j_inclusive = min(df_temp$max_j, na.rm = T)
min_j_inclusive = max(df_temp$min_j, na.rm = T)
max_j = max(filter(data, j<99)$j, na.rm = T)
min_j = min(filter(data, j<99)$j, na.rm = T)
```



```{r max-min-event-times-table}
data.frame(max_j = max_j, min_j = min_j) %>%
  kbl(caption = "Maximum \\& Minimum Event Time Values",
      col.names = c('Max j', 'Min j'),
      align = 'cc') %>%
  kable_styling(latex_options = "HOLD_position")
```

Notice from Figure \ref{fig:max_event_time_distribution} that we have a wide
range of maximum event times across our panel of states. One state even has a
maximum event time of 0 -- meaning they only added primary seat belt laws in the
last year of our panel (2003). This means we will have an unbalanced panel if we
run a regression on all possible event time dummies. In fact, we will still have
an unbalance panel if we create max and min event time bins to aggregate early
and late periods (an indicator for a event times greater than 5 and an indicator
for all event times less than -5), we will still have an unbalanced panel.

```{r max_event_time_distribution, message=F, fig.width=4, fig.height=3, fig.align='center', fig.cap='Treated States, maximum event time histogram'}
df_temp %>%
    arrange(max_j) %>%
    filter(!is.na(max_j), max_j < 99) %>%
    select(max_j) %>%
    ggplot(aes(x=max_j), data=.) +
    geom_histogram() +
    xlab("max event period")
```

To estimate the event study treatment effects, corresponding regression equation is:
\[
Y_{st} = \alpha + \sum\limits_{j=min\_t}^{max\_t} \tau_j D_{jst}
    + \gamma_s + \delta_t + \varepsilon_{st} + u_{st}
\]
Note that we are estimating the regression with state and year fixed effects. In
practice, we would want to omit a specific event time indicator so all our treatment
effects are measured with respect to that event time. If we keep all our indicators,
then R will implicitly choose which to event time indicator to omit for us because
the event time dummies, along with state and year fixed effects, are colinear.


```{r create event time dummies}
# Function for adding dummies to a dataframe for all uniuqe values between given numbers
create_dummies = function(df, colname, min_value, max_value) {
    # Create dummies for each value of colname between min_value and max_value
    df1 = df
    for (val in min_value:max_value) {
        df1 = mutate(df1, "{colname}_{val}" := ifelse(eval(as.symbol(colname)) == val, 1, 0))
    }
    return(df1)
}

# Create order of dummies for dataframe (then used for regression table)
name_order1 = paste('j', min_j_inclusive:max_j_inclusive, sep='_')
# Create Dummies that make a balanced panel
# (only dummies for event times j that are shared across all states)
df_few_dummies = create_dummies(data,
                             colname = 'j',
                             min_value = min_j_inclusive,
                             max_value = max_j_inclusive) %>%
    relocate(all_of(name_order1)) %>% 
    # Change "j_..." to "..._ET" because LaTeX doesn't like j_-3 type variable names
    rename_with(~ paste0(str_replace(., 'j_', ''), '_ET'), contains("j_"))

# Create order of dummies for dataframe (then used for regression table)
name_order2 = paste('j', min_j:max_j, sep='_')
# Create Dummies for all possible event times
# (results in unbalanced panel over event times j)
df_all_dummies = dummy_cols(data, select_columns = 'j') %>%
    select(-j_99) %>%
    filter(state != 99)  %>%
    relocate(all_of(name_order2)) %>% 
    rename_with(~ paste0(str_replace(., 'j_', ''), '_ET'), contains("j_"))
```

We can see column (1) of  Table \ref{tab:event-study-dummy-trap} that the indicator for event time +19
was omitted for the regression. However, for interpretability, we'd rather have
the treatment effects relative to a period closer to the year of initial treatment.

```{r Run dummy-trap event study regression}
reg_1a = df_all_dummies %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('_ET')) %>%
    lm(ln_fat_pc ~ ., data = .)

```



<!--
Notes:
the panel is very unbalanced. Even after using -5 and +5 thresholds, there are
still 5 states that have max event time less than 5. What happens to these?

order of the regression table is not correct, despite using the `order` arg.

Order the columns of the dataframe, then hopefully will be in order for regression
and for plotting
-->
















## Part (b)
**Estimate another event study regression using all the event time indicators
save one that you choose to omit. Generate a plot of the event study
coefficients.**

```{r Omit t-1 dummy}
reg_1b = df_all_dummies %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('_ET'), -`-1_ET`) %>%
    lm(ln_fat_pc ~ ., data = .)

```

We have chosen to omit the event time -1 from the regression so the other event
time inidicator coefficients can be interpreted as relative to the year immediately
before the passage of the primary seat belt law.
Column (2) of Table \ref{tab:event-study-dummy-trap} shows that the -1 event time
period was omitted, and we we see that all of the treatment effects occuring before
event time -1 are not significantly different from zero, whereas all the event time
coefficient estimates for after event time -1 are negative and all are signficantly
less than zero starting with event period 5.

```{r event-study-table, results='asis'}
stargazer(reg_1a, reg_1b,
          title = "Event Study Regressions\\label{tab:event-study-dummy-trap}",
          dep.var.caption = "Log(Fatality per Population)",
          dep.var.labels.include = FALSE,
          column.labels = c("Event Study a", "Event Study b"),
          omit = c("state", "year"),
          add.lines=list(c('Chose dummy to omit', 'No', 'Yes')),
          font.size = "footnotesize", column.sep.width = "1pt", no.space = TRUE,
          omit.stat=c("f", "ser"),
          single.row = TRUE,
          digits = 4, type = table_type, header = FALSE)


```
















\newpage
## Part (c)
**Create minimum and maximum event time indicators that correspond to bins of
event time < -5 and event time > 5 respectively. Appropriately specify and
estimate an event study regression using these min and max event time
indicators. Generate a plot of the event study coefficients. Explain which
specification you prefer, this one or the one in part (b).**


```{r Create threshold event time dummies}
# Function for adding dummies to a dataframe for all uniuqe values between given numbers
create_dummies_threshold = function(df, colname, min_value, max_value, suffix = NULL) {
    # Create indicator variables for each value of colname between min_value and max_value
    # then create indicator variables for all values of colname below min_value
    # and another for above max_value
    if (is.null(suffix)) {suffix = colname}
    df1 = df
    # add aggregate indicator for all values below min_value
    df1 = mutate(df1, "below_{suffix}" := ifelse(eval(as.symbol(colname)) < min_value, 1, 0))
    # add all indicators in between min and max_value
    for (val in min_value:max_value) {
        df1 = mutate(df1, "{val}_{suffix}" := ifelse(eval(as.symbol(colname)) == val, 1, 0))
    }
    # add aggregate indicator for all values above max_value
    df1 = mutate(df1, "above_{suffix}" := ifelse(eval(as.symbol(colname)) > max_value, 1, 0))
    return(df1)
}


# Create Dummies that make a balanced panel
# (only dummies for event times j that are shared across all states)
df_threshold_dummies = create_dummies_threshold(data,
                                          colname = 'j',
                                          min_value = -5,
                                          max_value = 5,
                                          suffix = 'ET')

```

```{r Regression with threshold event time dummies}
reg_1c = df_threshold_dummies %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('_ET'), -`-1_ET`) %>%
    lm(ln_fat_pc ~ ., data = .)

```


```{r Event Study table with Thresholds, results='asis'}
stargazer(reg_1c,
          title = "Event Study Regression with Threshold Indicators\\label{tab:event-study-thresholds}",
          dep.var.caption = "Log(Fatality per Population)",
          dep.var.labels.include = FALSE,
          column.labels = c("Event Study c"),
          omit = c("state", "year"),
          add.lines=list(c('Chose dummy to omit', 'Yes'), c('Agg. Threshold Indicators', 'Yes')),
          font.size = "footnotesize", column.sep.width = "1pt", no.space = TRUE,
          omit.stat=c("f", "ser"),
          single.row = TRUE,
          notes = c("below\\_ and above\\_ variables are aggregate indicators for",
                    "all event times that are below -5 and above 5, respectively."),
          digits = 4, type = table_type, header = FALSE)

plot_text1 = "(red) Plot of all possible event-time coefficients and 95\\% confidence intervals from Table \\ref{tab:event-study-dummy-trap}; (blue) plot of event-time coefficients and 95\\% confidence intervals for event-times from years before the passage of the primary seat belt law to 5 years after and coefficents for aggregate event-time indicators of more than 5 years before and more than 5 years after the law passed, plotted at x-values of -6 and 6, respectively (from Table \\ref{tab:event-study-thresholds})"

```



```{r Event Study Plot with Thresholds, fig.width=8, fig.cap=plot_text1}
new_varname = function(oldname, min_value, max_value) {
    name = str_replace_all(oldname, "`","")
    name = str_replace(name, "_ET", "")
    name = str_replace(name, "below", paste("<", min_value))
    name = str_replace(name, "above", paste(">", max_value))
    return(name)
}

xvalue = function(oldname, min_value = NULL, max_value = NULL) {
    name = str_replace_all(oldname, "`","")
    name = str_replace(name, "_ET", "")
    if (!is.null(min_value)) {
        name = str_replace(name, "below", as.character(min_value - 1))
        name = str_replace(name, "above", as.character(max_value + 1))
    }
    return(as.numeric(name))
}

regression_dataframe = function(reg, reg_type, min_value = NULL, max_value = NULL, suffix = 'ET') {
    df = data.frame(coef = names(reg$coefficients), 
                    value = reg$coefficients,
                    lower = confint(reg)[,1],
                    upper = confint(reg)[,2],
                    reg_type = reg_type) %>%
        filter(grepl(suffix, coef)) %>%
        mutate(x_tick = new_varname(coef, min_value, max_value),
               event_time = xvalue(coef, min_value, max_value)) %>%
        return()
}

df1 = rbind(
    regression_dataframe(reg_1b, "all indicators"),
    regression_dataframe(reg_1c, "max-min indicators", min_value = -5, max_value = 5)
)

df1 %>%
    ggplot(aes(x=event_time, y=value, color = reg_type)) + 
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.1) +
    geom_line() +
    geom_point() +
    geom_hline(yintercept = 0) +
    labs(color = "Parameters estimated") +
    xlab("Event Time (years since passage of primary seat belt law)") +
    ylab("Coefficient Value") +
    annotate(geom = "segment", x = 3, y = -0.3, xend = 5.7, yend = -0.14,
             arrow = arrow(length = unit(2, "mm"))) +
    annotate(geom = "text", x = 3, y = -0.32, 
             label = "(blue) coeffcient on >5 years after passage", 
             hjust = "center") +
    annotate(geom = "segment", x = -4.5, y = -0.15, xend = -5.9, yend = 0.018,
             arrow = arrow(length = unit(2, "mm"))) +
    annotate(geom = "text", x = -8, y = -0.17, 
             label = "(blue) coeffcient on >5 years before passage", 
             hjust = "center")
    
```



<!--
We could add another regression here where we prune the data to be balanced in
event time with threshold dummies.

Also could do post-treatment event time indicators interacted with treatment cohort
indicators and plot a graph of the different cohort-specific treatment estimates
-->




\newpage
## Part (d)
**What happens to your estimates from part (b) if you exclude the “pure control”
states from your sample? What about if you exclude the pure controls in part
(c)?**


```{r Regressions excluding pure control states}
# Regression with all possible event-time indicators, removing pure control states
reg_1b2 = df_all_dummies %>%
    group_by(state) %>%
    filter(mean(primary) > 0) %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('_ET'), -`-1_ET`) %>%
    lm(ln_fat_pc ~ ., data = .)

# Regression with max, min aggregated event-time indicators, removing pure control states
reg_1c2 = df_threshold_dummies %>%
    group_by(state) %>%
    filter(mean(primary) > 0) %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('_ET'), -`-1_ET`) %>%
    lm(ln_fat_pc ~ ., data = .)

```


```{r Event study table dropping pure controls, results='asis'}
stargazer(reg_1b, reg_1b2, reg_1c, reg_1c2,
          title = "Event Study Regressions with and without Pure Control States\\label{tab:event-study-no-controls}",
          dep.var.caption = "Log(Fatality per Population)",
          dep.var.labels.include = FALSE,
          column.labels = c("All indicators",
                            "All indicators",
                            "Min-max indicators",
                            "Min-max indicators"),
          omit = c("state", "year"),
          add.lines=list(c('Agg. Threshold Indicators', 'No', 'No', 'Yes', 'Yes'), 
                         c('Include Pure Controls', 'Yes', 'No', 'Yes', 'No')),
          font.size = "footnotesize", column.sep.width = "1pt", no.space = TRUE,
          omit.stat=c("f", "ser"),
          single.row = TRUE,
          digits = 4, type = table_type, header = FALSE)


```



For the all-event-times-indicators regressions from part (b), we can see in
Table \ref{tab:event-study-no-controls} that for event-time indicators
after the primary seat belt law is passed (event times $\geq 0$), the
coefficients change from being all negative and mostly significant to being all
insignificant at the 0.1 level and mixed signs. Interestingly, the coefficients
on the event-time indicators for times before the passage of the law become
significantly negative -- indicating that the passage of the law might have
caused an increase in traffic fatalities in states in the treatment group (i.e.,
the effect of treatment on the treated might be the opposite sign we expect).
However, we also should note that the coefficient on event time 19 (19 years
after the passage of the law) is dropped by the regression because of
colinearity -- without pure control states, the combination of state and year
fixed effects with indicators for all but one event times becomes colinear.

Because we have omitted the coefficient on event time 19 and event time 0, we
cannot readily interpret the coefficients in column (2) of Table
\ref{tab:event-study-no-controls}.

If we focus on columns (3) and (4) from Table
\ref{tab:event-study-no-controls}, we can see removing the pure control
states (column 4) reduces the significance and magnitude of all our
coefficients, but the last two coeffcients for event time 5 (`5\_ET') and the
aggregate of all event times greater than 5 (above\_ET) are still signficant
and negative. One way to interpret this is that the treatment effect on the
treated is smaller than that of the average treatment effect. We also could
hypothesize that the states that passed the primary seat belt laws during our
study period were doing something other than passing the primary law and
something different from the pure control states to reduce traffic fatalities,
so our comparison within the treatment states (column 4) estimates a smaller
effect than when we compare our treated states to the pure control states.








\newpage
## Part (e)
**Overall, does the event study regression make you more confident or less
confident that seat belt laws reduce fatalities (relative to the fixed effects
results that you estimated on the last problem set)? Briefly explain.**

















\newpage
## Part (f$^*$)
**Building off the event study regression from part (c), estimate the
interaction weighted event study estimator from Sun and Abraham (2020). As a reminder, the
interacted event study regression takes the standard event time indicators
(without any binning) and interacts each one with a cohort indicator (a cohort
refers to a group of states that share the same date on which they were
first treated). You then form the estimate for event time coefficient $\tau_j$ 
by averaging the estimates of the cohort-specific $\tau_j$ using
the weights described in Sun and Abraham (2020).**


<!-- A FEW TIPS:
• Given the interacted specification’s complexity and the potential
colinearities involved, you may find it easier to manually generate the needed
interaction terms rather than using factor-variable commands in Stata/R (e.g.
Stata’s xi com- mand).

• Some of the interactions between cohort indicators and event time indicators
will generate constants, because the event time indicator is too early or too
late to be identified for a given cohort. Think carefully about this. • In the
case of the coefficients for j < -5 and j > 5, note that you will be averaging
across cohorts and across event time coefficients.

• You will need to compute the share that each cohort con- tributes to each
event time indicator to get the right weights. E.g. suppose that the event time
indicator for j = +5 were informed only by cohort 1, containing 3 states, and
cohort 2, containing 1 state. Then the weights for event time indicator j = +5
would be 0.75 for cohort 1 and 0.25 for cohort 2.

• The paper references an eventstudyweights Stata package to estimate the
cohort-by-event-time weights. Be aware that (as of 2020) this package computes
the implicit weights that a standard event study regression applies to each of
the cohort- by-event time coefficients, not the weights that should be used to
generate the interaction weighted event study estimator.
-->
















\newpage
<!--=========================================================================-->
# Problem 2
<!--=========================================================================-->
**We now apply the synthetic control methods from Abadie et al (2010).**

<!--
Some preliminaries: Abadie et al have created a downloadable “canned”
command to run the synthetic control method. To download the com-
mand for Stata you will need to have an updated version of Stata and
be running Stata on a Mac, PC or Unix/Linux. R code is also available.
In Stata type ‘update all’ and then ‘update swap’. Next, go to the web-
site below and follow the instructions. There is also downloadable code
for Matlab at http://web.stanford.edu/~jhain/synthpage.html (note:
blindly copying and pasting this URL may not reproduce the tilde)
 -->


## Part (a)
**We created an aggregate “treatment” state (state number 99 or “TU”) which
combines the (population weighted) data from the first 4 states to have a
primary seatbelt law (CT, IA, NM, TX). Please use this state as the “treatment”
state in the synthetic control analysis.**

### ------ a.i
**Compare the average pre-period log traffic fatalities per capita of the TU
site to that of the average of all the “control” states. Next, graph the
pre-period log traffic fatalities by year for the pre-period for both the TU and
the average of the control group. Interpret.**

```{r Compare averages between TU and all controls}
# Calculate average pre-period log traffic fatalities per capita
preperiod_years = data %>%
    filter(state == 99, primary == 0) %>%
    select(year)

means = data %>%
    group_by(state) %>%
    # previously set j = 99 for pure control states (mean(primary) = 0)
    mutate(control = ifelse(mean(primary) > 0, 0, 1)) %>%
    filter(control == 1 | state == 99) %>%
    filter(year %in% preperiod_years$year) %>%
    group_by(control) %>%
    summarize(avg = mean(ln_fat_pc))
means %>%
    select(avg) %>%  # control = 0 on top ==> TU on top
    t() %>%  # control = 0 on left ==> TU on left
    kbl(caption = "Average Pre-period log(traffic fatalities per capita)\\label{tab:avg-fat-TU}",
        col.names = c('Aggregate Treatment State', 'Aggregate Control State'),
        row.names = F,
        align = 'cc') %>%
    kable_styling(latex_options = "HOLD_position")
```

<!-- Reference: Table \ref{tab:avg-fat-TU} -->

<<<<<<< HEAD
```{r Plot: pre-trends, message=F}
=======
```{r Plot: pre-trends}
>>>>>>> ba6ba572a8b87d448f54e144bae47391ef874981
data %>%
    group_by(state) %>%
    # previously set j = 99 for pure control states (mean(primary) = 0)
    mutate(control = ifelse(mean(primary) > 0, 0, 1),
<<<<<<< HEAD
           treated = ifelse(state == 99, 'Yes', 'No')) %>%
=======
           treated = ifelse(state == 99, 1, 0)) %>%
>>>>>>> ba6ba572a8b87d448f54e144bae47391ef874981
    filter(control == 1 | state == 99) %>%
    filter(year %in% preperiod_years$year) %>%
    group_by(year, treated) %>%
    summarize(year_avg = mean(ln_fat_pc)) %>%
    ggplot(aes(x=year, y=year_avg, color=factor(treated))) +
    geom_line() +
    geom_point() +
    geom_hline(yintercept = filter(means, control==0)$avg, color='cyan') +
    geom_hline(yintercept = filter(means, control==1)$avg, color='red') +
<<<<<<< HEAD
    labs(color = "Primary Seatbelt Law") +
    xlab("Year") +
    ylab("log(Fatalities per capita)") +
    ggtitle("Pre-period annual avereage log(Fatalilties per capita)") +
    annotate(geom = "text", x = 1984, y = -1.56, 
             label = "Avg for control\n states over pre-periods", 
             hjust = "center") +
    annotate(geom = "text", x = 1984, y = -1.34, 
             label = "Average for the aggregate\n treated unit over pre-periods", 
             hjust = "center")
=======
    labs(color = "Treated") +
    xlab("Year") +
    ylab("log(Fatalities per capita)") +
    ggtitle("Pre-period annual avereage log(Fatalilties per capita)")
>>>>>>> ba6ba572a8b87d448f54e144bae47391ef874981
```















### ------ a.ii
**Compare the dependent variable between the TU site and each control state for
the year before the treatment. Which control state best matches the TU? Now
compare this state’s covariates with the TU covariates. Do they appear similar?
What might this imply for in terms of using this state as the counterfactual
state?**


















\newpage
## Part (b)
**Apply the synthetic control method using the available covariates and
pre-treatment outcomes to construct a synthetic control group.**

### ------ b.i
**Discuss the synthetic control method including its benefits and potential
drawbacks.**















### ------ b.ii
**Use the software package provided by Abadie et al to apply the synthetic
control method. (You are free to use either Stata, Matlab, or R but answers will
be provided in Stata and R only). Please be sure to state precisely what the
command is doing and how you determined your preferred specification.**


















\newpage
## Part (c)
**Graphical interpretation and treatment significance.**

### ------ c.i
**Generate graphs plotting the gap between the TU and the synthetic control
group under both your preferred specification and a few other specifications
you tried.**















### ------ c.ii
**Compare the graph plotting the gap between the TU and the synthetic control
group under your preferred specification with the graphs plotting the gap
between each control state and its “placebo” treatment. Do you conclude that the
treatment was significant? Why or why not?**















### ------ c.iii
**Create a graph of the post-treatment/pre-treatment prediction ratios of the
Mean Squared Prediction Errors (MSPE) for the actual and “plecebo” treatment
gaps in (ii). [See Abadie et al. for an example]. Do you conclude that the
treatment was significant? Why or why not?**




























\newpage
## Part (d)
**How do your synthetic control results compare to your fixed effects results
from Question (3) in the last problem set? Interpret any differences.**





















\newpage
# Appendix A: R Code

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```





















