---
title: "ARE 213 PS 2b"
author: "S. Sung, H. Husain, T. Woolley, A. Watt"
email: aaron@acwatt.net
date: "2021-11-23"
output:
  pdf_document:
    toc: true
    toc_depth: 2
header-includes:
   - \usepackage{dcolumn}
   - \usepackage{amsmath}
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'ARE_213_PS2b.pdf')) })
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = F)
```
<!--
R version 3.6.3 (2020-02-29)
Purpose of script: run code necessary for ps2b for ARE 213

Notes: Need to open ps2b.Rmd from the ps2b folder (without Rstudio being started first)
if Rstudio is already started, the working directory will not be set
to the ps2b/ folder

\usepackage{dcolumn}: dcolumn is needed in latex compilation for multicolumn tables
-->

```{r Settings}
# stargazer table type (html, latex, or text)
# Change to latex when outputting to PDF, html when outputting to html
table_type = "latex"

```




```{r packages, include=F}
# install.packages("Synth")
library(tidyverse)
library(haven)
library(stargazer)
library(ggplot2)
library(tinytex)
library(Synth)
library(kableExtra)
# library(plm)
# library(lmtest)
# library(sandwich)
# library(gridExtra)
# library(grid)
# library(gtable)
library(fastDummies)
# library(EnvStats)


```



\newpage
<!--=========================================================================-->
# Problem 1
<!--=========================================================================-->
**We first estimate an event study specification.**

## Part (a)
**First determine the minimum and maximum event time values that you can
estimate in this data set. Code up a separate event time indicator for each
possible value of event time in the data set. Estimate an event study regression
using all the event time indicators. What happens?**
\vspace{1em}


```{r Load Data, eval=T}
# Load data from PS2a with previous log variables
data = read_dta('traffic_safety2.dta') %>%
    mutate(fat_pc = fatalities/population,
           ln_fat_pc = log(fat_pc),
           ln_tvmt_pc = log(totalvmt/population),
           ln_precip = log(precip),
           ln_rspeed = log(rural_speed), 
           ln_uspeed = log(urban_speed))

```


These are the minimum and maximum event times that exist in the data for states
that enacted a primary seat belt law in our study period (1981-2003).

```{r Determine event time values}
# Create list of event dates for states that passed primary laws in our study
event_dates = data %>%
    group_by(state) %>%
    mutate(event = primary - lag(primary), # event=1 ==> first year primary=1
           event_year = year) %>%
    filter(event == 1) %>%
    select(state, event_year)

# Add year of primary event and event time (t) to dataframe
data = data %>%
    left_join(event_dates, by='state') %>%
    mutate(j = ifelse(is.na(event_year), 99, year - event_year))
    # t = 99 ==> control state (doesn't pass primary during study period)

# Table of max and min event times
# Shouldn't these be our event study thresholds?
df_temp = data %>%
    filter(j < 99) %>%
    group_by(state) %>%
    summarize(min_j = min(j), max_j = max(j))

df_temp %>%
    arrange(max_j) %>%
    filter(!is.na(max_j), max_j < 99) %>%
    select(max_j) %>%
    ggplot(aes(x=max_j), data=.) +
    geom_histogram() +
    xlab("max event period") +
    ggtitle("Treated States, maximum event time histogram")

max_j_inclusive = min(df_temp$max_j, na.rm = T)
min_j_inclusive = max(df_temp$min_j, na.rm = T)
max_j = max(filter(data, j<99)$j, na.rm = T)
min_j = min(filter(data, j<99)$j, na.rm = T)

data.frame(max_j = max_j, min_j = min_j) %>%
  kbl(caption = "Maximum \\& Minimum Event Time Values",
      col.names = c('Max j', 'Min j'),
      align = 'cc') %>%
  kable_styling(latex_options = "HOLD_position")
```



```{r create event time dummies}
create_dummies = function(df, colname, min_value, max_value) {
    # Create dummies for each value of colname between min_value and max_value
    df1 = df
    for (val in min_value:max_value) {
        df1 = mutate(df1, "{colname}_{val}" := ifelse(eval(as.symbol(colname)) == val, 1, 0))
    }
    return(df1)
}

name_order1 = paste('j', min_j_inclusive:max_j_inclusive, sep='_')
df_few_dummies = create_dummies(data,
                             colname = 'j',
                             min_value = min_j_inclusive,
                             max_value = max_j_inclusive) %>%
    relocate(all_of(name_order1))

names(df_few_dummies) = gsub(x = names(df_few_dummies), 
                             pattern = "j\\_", 
                             replacement = "j")

name_order2 = paste('j', min_j:max_j, sep='_')
df_all_dummies = dummy_cols(data, select_columns = 'j') %>%
    select(-j_99) %>%
    filter(state != 99)  %>%
    relocate(all_of(name_order2))

names(df_all_dummies) = gsub(x = names(df_all_dummies), 
                             pattern = "j\\_", 
                             replacement = "")
```

The corresponding regression equation is:
\[
Y_{st} = \alpha + \sum\limits_{j=min\_t}^{max\_t} \tau_j D_{jst}
    + \gamma_s + \delta_t + \varepsilon_{st} + u_{st}
\]
so we estimate the regression with state and year fixed effects.

```{r Run dummy-trap event study regression, results='asis'}
reg_1a = df_all_dummies %>%
    mutate(state=factor(state), year=factor(year)) %>%
    select(ln_fat_pc, state, year, contains('j_')) %>%
    lm(ln_fat_pc ~ ., data = .)


stargazer(reg_1a, 
          title = "Event Study Regressions",
          dep.var.caption = "Log(Fatality per Population)",
          dep.var.labels.include = FALSE,
          # model.names = FALSE,
          column.labels = c("Event Study a"),
          # keep = paste0('^j', (-5):5, '$'),
          # order = paste0('/^t_', (-5):5, '$/'),
          # perl = T,
          # covariate.labels = as.character((-5:5)),
          add.lines=list(c('Choose dummy to omit', 'No')),
          font.size = "footnotesize", column.sep.width = "1pt", no.space = TRUE,
          omit.stat=c("f", "ser"),
          digits = 4, type = table_type, header = FALSE)


# stargazer(reg_1a, 
#           title = "Event Study Regressions",
#           dep.var.caption = "Log(Fatality per Population)",
#           dep.var.labels.include = FALSE,
#           # model.names = FALSE,
#           column.labels = c("Event Study a"),
#           keep = paste0('/^t', -5:5, '$/'),
#           order = paste0('/^t', -5:5, '$/'),
#           perl = T,
#           covariate.labels = as.character((-5:5)),
#           add.lines=list(c('Choose dummy to omit', 'No')),
#           font.size = "footnotesize", column.sep.width = "1pt", no.space = TRUE,
#           omit.stat=c("f", "ser"),
#           digits = 4, type = table_type, header = FALSE)
```



<!--
Notes:
the panel is very unbalanced. Even after using -5 and +5 thresholds, there are
still 5 states that have max event time less than 5. What happens to these?

order of the regression table is not correct, despite using the `order` arg.

Order the columns of the dataframe, then hopefully will be in order for regression
and for plotting
-->















\newpage
## Part (b)
**Estimate another event study regression using all the event time indicators
save one that you choose to omit. Generate a plot of the event study
coefficients.**

```{r Omit t-1 dummy}
reg_1b = lm(ln_fat_pc ~ .,
   data = df_all_dummies %>%
       mutate(state=factor(state), year=factor(year)) %>%
       select(ln_fat_pc, state, year, contains('j_'), -`-1`))
```
















\newpage
## Part (c)
**Create minimum and maximum event time indicators that correspond to bins of
event time < -5 and event time > 5 respectively. Appropriately specify and
estimate an event study regression using these min and max event time
indicators. Generate a plot of the event study coefficients. Explain which
specification you prefer, this one or the one in part (b).**

















\newpage
## Part (d)
**What happens to your estimates from part (b) if you exclude the “pure control”
states from your sample? What about if you exclude the pure controls in part
(c)?**

















\newpage
## Part (e)
**Overall, does the event study regression make you more confident or less
confident that seat belt laws reduce fatalities (relative to the fixed effects
results that you estimated on the last problem set)? Briefly explain.**

















\newpage
## Part (f$^*$)
**Building off the event study regression from part (c), estimate the
interaction weighted event study estimator from Sun and Abraham (2020). As a reminder, the
interacted event study regression takes the standard event time indicators
(without any binning) and interacts each one with a cohort indicator (a cohort
refers to a group of states that share the same date on which they were
first treated). You then form the estimate for event time coefficient $\tau_j$ 
by averaging the estimates of the cohort-specific $\tau_j$ using
the weights described in Sun and Abraham (2020).**


<!-- A FEW TIPS:
• Given the interacted specification’s complexity and the potential
colinearities involved, you may find it easier to manually generate the needed
interaction terms rather than using factor-variable commands in Stata/R (e.g.
Stata’s xi com- mand).

• Some of the interactions between cohort indicators and event time indicators
will generate constants, because the event time indicator is too early or too
late to be identified for a given cohort. Think carefully about this. • In the
case of the coefficients for j < -5 and j > 5, note that you will be averaging
across cohorts and across event time coefficients.

• You will need to compute the share that each cohort con- tributes to each
event time indicator to get the right weights. E.g. suppose that the event time
indicator for j = +5 were informed only by cohort 1, containing 3 states, and
cohort 2, containing 1 state. Then the weights for event time indicator j = +5
would be 0.75 for cohort 1 and 0.25 for cohort 2.

• The paper references an eventstudyweights Stata package to estimate the
cohort-by-event-time weights. Be aware that (as of 2020) this package computes
the implicit weights that a standard event study regression applies to each of
the cohort- by-event time coefficients, not the weights that should be used to
generate the interaction weighted event study estimator.
-->
















\newpage
<!--=========================================================================-->
# Problem 2
<!--=========================================================================-->
**We now apply the synthetic control methods from Abadie et al (2010).**

<!--
Some preliminaries: Abadie et al have created a downloadable “canned”
command to run the synthetic control method. To download the com-
mand for Stata you will need to have an updated version of Stata and
be running Stata on a Mac, PC or Unix/Linux. R code is also available.
In Stata type ‘update all’ and then ‘update swap’. Next, go to the web-
site below and follow the instructions. There is also downloadable code
for Matlab at http://web.stanford.edu/~jhain/synthpage.html (note:
blindly copying and pasting this URL may not reproduce the tilde)
 -->


## Part (a)
**We created an aggregate “treatment” state (state number 99 or “TU”) which
combines the (population weighted) data from the first 4 states to have a
primary seatbelt law (CT, IA, NM, TX). Please use this state as the “treatment”
state in the synthetic control analysis.**

### ------ a.i
**Compare the average pre-period log traffic fatalities per capita of the TU
site to that of the average of all the “control” states. Next, graph the
pre-period log traffic fatalities by year for the pre-period for both the TU and
the average of the control group. Interpret.**

















### ------ a.ii
**Compare the dependent variable between the TU site and each control state for
the year before the treatment. Which control state best matches the TU? Now
compare this state’s covariates with the TU covariates. Do they appear similar?
What might this imply for in terms of using this state as the counterfactual
state?**


















\newpage
## Part (b)
**Apply the synthetic control method using the available covariates and
pre-treatment outcomes to construct a synthetic control group.**

### ------ b.i
**Discuss the synthetic control method including its benefits and potential
drawbacks.**















### ------ b.ii
**Use the software package provided by Abadie et al to apply the synthetic
control method. (You are free to use either Stata, Matlab, or R but answers will
be provided in Stata and R only). Please be sure to state precisely what the
command is doing and how you determined your preferred specification.**


















\newpage
## Part (c)
**Graphical interpretation and treatment significance.**

### ------ c.i
**Generate graphs plotting the gap between the TU and the synthetic control
group under both your preferred specification and a few other specifications
you tried.**















### ------ c.ii
**Compare the graph plotting the gap between the TU and the synthetic control
group under your preferred specification with the graphs plotting the gap
between each control state and its “placebo” treatment. Do you conclude that the
treatment was significant? Why or why not?**















### ------ c.iii
**Create a graph of the post-treatment/pre-treatment prediction ratios of the
Mean Squared Prediction Errors (MSPE) for the actual and “plecebo” treatment
gaps in (ii). [See Abadie et al. for an example]. Do you conclude that the
treatment was significant? Why or why not?**




























\newpage
## Part (d)
**How do your synthetic control results compare to your fixed effects results
from Question (3) in the last problem set? Interpret any differences.**





















\newpage
# Appendix A: R Code

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```





















